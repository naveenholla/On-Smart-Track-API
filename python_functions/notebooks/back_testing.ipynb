{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import Timestamp\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import math\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "import matplotlib.dates as mpl_dates\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sanitize(df):    \n",
    "    if df.empty:\n",
    "        return\n",
    "    if len(df.columns) > 0:\n",
    "        common_names = {\n",
    "            \"Date\": \"date\",\n",
    "            \"Time\": \"time\",\n",
    "            \"Timestamp\": \"timestamp\",\n",
    "            \"Datetime\": \"datetime\",\n",
    "            \"Open\": \"open\",\n",
    "            \"High\": \"high\",\n",
    "            \"Low\": \"low\",\n",
    "            \"Close\": \"close\",\n",
    "            \"Adj Close\": \"adj_close\",\n",
    "            \"Volume\": \"volume\",\n",
    "            \"Dividends\": \"dividends\",\n",
    "            \"Stock Splits\": \"split\",\n",
    "            \"open_price\": \"open\",\n",
    "            \"high_price\": \"high\",\n",
    "            \"low_price\": \"low\",\n",
    "            \"close_price\": \"close\",\n",
    "            \"traded_quantity\": \"volume\",\n",
    "        }\n",
    "        # Preemptively drop the rows that are all NaNs\n",
    "        # Might need to be moved to AnalysisIndicators.__call__() to be\n",
    "        #   toggleable via kwargs.\n",
    "        # df.dropna(axis=0, inplace=True)\n",
    "        # Preemptively rename columns to lowercase\n",
    "        df.rename(columns=common_names, errors=\"ignore\", inplace=True)\n",
    "        \n",
    "        col_types = {\n",
    "            \"open\": float,\n",
    "            \"high\": float,\n",
    "            \"low\": float,\n",
    "            \"close\": float,\n",
    "        }\n",
    "        \n",
    "        df = df.astype(col_types)\n",
    "\n",
    "        # Preemptively lowercase the index\n",
    "        index_name = df.index.name\n",
    "        if index_name is not None:\n",
    "            df.index.rename(index_name.lower(), inplace=True)\n",
    "        else:\n",
    "            df.set_index(pd.DatetimeIndex(df['date']))\n",
    "            \n",
    "        return df\n",
    "    else:\n",
    "        raise AttributeError(f\"[X] No columns!\")\n",
    "\n",
    "def _create_level_object(row, type):\n",
    "    levels = []\n",
    "    level = {}\n",
    "    level[\"type\"] = f\"{type} open\"\n",
    "    level[\"level\"] = np.round(row[\"open\"], 2)\n",
    "    levels.append(level)    \n",
    "    \n",
    "    level = {}\n",
    "    level[\"type\"] = f\"{type} high\"\n",
    "    level[\"level\"] = np.round(row[\"high\"])\n",
    "    levels.append(level)   \n",
    "    \n",
    "    level = {}\n",
    "    level[\"type\"] = f\"{type} low\"\n",
    "    level[\"level\"] = np.round(row[\"low\"])   \n",
    "    levels.append(level)   \n",
    "    \n",
    "    level = {}\n",
    "    level[\"type\"] = f\"{type} close\"\n",
    "    level[\"level\"] = np.round(row[\"close\"])  \n",
    "    levels.append(level)\n",
    "    return levels\n",
    "\n",
    "def _current_previous_levels(df, type):    \n",
    "    levels = []\n",
    "    \n",
    "    level = _create_level_object(df.iloc[-1], f\"current {type}\")\n",
    "    levels.extend(level)\n",
    "    \n",
    "    level = _create_level_object(df.iloc[-2], f\"previous {type}\")\n",
    "    levels.extend(level)\n",
    "    \n",
    "    return levels\n",
    "\n",
    "def monthly_levels(df):\n",
    "    df_values = df.resample('M').agg({'open':'first', 'high':'max', 'low': 'min', 'close':'last'})    \n",
    "    return _current_previous_levels(df_values, \"month\")\n",
    "\n",
    "def weekly_levels(df):\n",
    "    df_values = df.resample('W').agg({'open':'first', 'high':'max', 'low': 'min', 'close':'last'})    \n",
    "    return _current_previous_levels(df_values, \"week\")\n",
    "\n",
    "def firty_two_week_levels(df):\n",
    "    levels = []    \n",
    "    df['52W H'] = df['high'].rolling(window=252, center=False).max()\n",
    "    df['52W L'] = df['low'].rolling(window=252, center=False).min()\n",
    "    \n",
    "    level = {}\n",
    "    level[\"type\"] = f\"52 week high\"\n",
    "    level[\"level\"] = np.round(df['52W H'].iloc[-1], 2)\n",
    "    levels.append(level) \n",
    "    \n",
    "    level = {}\n",
    "    level[\"type\"] = f\"52 week low\"\n",
    "    level[\"level\"] = np.round(df['52W L'].iloc[-1], 2)\n",
    "    levels.append(level)\n",
    "    \n",
    "    return levels\n",
    "\n",
    "def _support(df, index, n1, n2): \n",
    "    #n1 n2 before and after candle index    \n",
    "    for i in range(index-n1+1, index+1):\n",
    "        if(df['low'][i] > df['low'][i-1]):\n",
    "            return False\n",
    "        \n",
    "    for i in range(index+1, index+n2+1):\n",
    "        if(df['low'][i] < df['low'][i-1]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def _resistance(df, index, n1, n2):\n",
    "    #n1 n2 before and after candle index     \n",
    "    for i in range(index-n1+1, index+1):\n",
    "        if(df['high'][i] < df['high'][i-1]):\n",
    "            return False\n",
    "        \n",
    "    for i in range(index+1, index+n2+1):\n",
    "        if(df['high'][i] > df['high'][i-1]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#method 1: fractal candlestick pattern\n",
    "# determine bullish fractal \n",
    "def _is_support(df,i):  \n",
    "  cond1 = df['low'][i] < df['low'][i-1]   \n",
    "  cond2 = df['low'][i] < df['low'][i+1]   \n",
    "  cond3 = df['low'][i+1] < df['low'][i+2]   \n",
    "  cond4 = df['low'][i-1] < df['low'][i-2]  \n",
    "  return (cond1 and cond2 and cond3 and cond4) \n",
    "\n",
    "# determine bearish fractal\n",
    "def _is_resistance(df,i):  \n",
    "  cond1 = df['high'][i] > df['high'][i-1]   \n",
    "  cond2 = df['high'][i] > df['high'][i+1]   \n",
    "  cond3 = df['high'][i+1] > df['high'][i+2]   \n",
    "  cond4 = df['high'][i-1] > df['high'][i-2]  \n",
    "  return (cond1 and cond2 and cond3 and cond4)\n",
    "\n",
    "# to make sure the new level area does not exist already\n",
    "def _is_far_from_level(value, unique_levels, df):\n",
    "    # Clean noise in data by discarding a level if it is near another\n",
    "    # (i.e. if distance to the next level is less than the average candle size for any given day - this will give a rough estimate on volatility) \n",
    "    ave =  np.mean(df['high'] - df['low'])    \n",
    "    return np.sum([abs(value-level)<ave for _,level in unique_levels])==0\n",
    "\n",
    "# This function, given a price value, returns True or False depending on if it is too near to some previously discovered key level.\n",
    "def _distance_from_mean(mean, level, levels):\n",
    "    return np.sum([abs(level - y) < mean for y in levels]) == 0\n",
    "\n",
    "def remove_noise(df, levels, ltp):\n",
    "    # Clean noise in data by discarding a level if it is near another\n",
    "    # (i.e. if distance to the next level is less than the average candle size for any given day - this will give a rough estimate on volatility)\n",
    "    mean = np.mean(df['high'] - df['low'])\n",
    "    \n",
    "    unique_levels = []\n",
    "    for l in levels:\n",
    "        if _distance_from_mean(mean, l, unique_levels):\n",
    "            unique_levels.append(l)\n",
    "    return unique_levels\n",
    "      \n",
    "#method 1: fractal candlestick pattern\n",
    "def _fractal_candlestick_pattern_sr(df):\n",
    "  levels = []  \n",
    "  indexes = list(df.index.values)\n",
    "  for i in range(2,df.shape[0]-2):\n",
    "    index = Timestamp(indexes[i])\n",
    "    if _is_support(df,i):\n",
    "      l = df['low'][i]\n",
    "      if _is_far_from_level(l, levels, df):\n",
    "        levels.append((index,l))\n",
    "    elif _is_resistance(df,i):\n",
    "      l = df['high'][i]\n",
    "      if _is_far_from_level(l, levels, df):\n",
    "        levels.append((index,l))\n",
    "  return levels\n",
    "\n",
    "def fractal_candlestick_pattern_sr_2(df, n1=2, n2=2):\n",
    "  levels = []  \n",
    "  indexes = list(df.index.values)\n",
    "  for i in range(2,df.shape[0]-2):\n",
    "    index = Timestamp(indexes[i])\n",
    "    if _support(df,i, n1, n2):\n",
    "      l = df['low'][i]\n",
    "      if _is_far_from_level(l, levels, df):\n",
    "        levels.append((index,l))\n",
    "    elif _resistance(df,i, n1, n2):\n",
    "      l = df['high'][i]\n",
    "      if _is_far_from_level(l, levels, df):\n",
    "        levels.append((index,l))\n",
    "  return levels\n",
    "\n",
    "#method 2: window shifting method\n",
    "def window_shifting_method_sr(df, window=5):\n",
    "  levels = []\n",
    "  max_list = []\n",
    "  min_list = []\n",
    "  for i in range(window, len(df)-window):\n",
    "      high_range = df['high'][i-window:i+window-1]\n",
    "      current_max = high_range.max()\n",
    "      if current_max not in max_list:\n",
    "          max_list = []\n",
    "      max_list.append(current_max)\n",
    "      if len(max_list) == window and _is_far_from_level(current_max, levels, df):\n",
    "          levels.append((high_range.idxmax(), current_max))\n",
    "      \n",
    "      low_range = df['low'][i-window:i+window]\n",
    "      current_min = low_range.min()\n",
    "      if current_min not in min_list:\n",
    "          min_list = []\n",
    "      min_list.append(current_min)\n",
    "      if len(min_list) == window and _is_far_from_level(current_min, levels, df):\n",
    "          levels.append((low_range.idxmin(), current_min))\n",
    "  return levels\n",
    "\n",
    "def get_support_resistance(df, n1=2, n2=2, window=5):\n",
    "    #n1 n2 before and after candle index \n",
    "    all_pivots_dict = []\n",
    "    levels = fractal_candlestick_pattern_sr_2(df, n1, n2)\n",
    "    for level in levels:\n",
    "        point = np.round(level[1], 2)\n",
    "        \n",
    "        pivot = {}\n",
    "        pivot[\"type\"] = \"SR - fractal candlestick pattern\"\n",
    "        pivot[\"date\"]=level[0].to_pydatetime()\n",
    "        pivot[\"level\"] = point\n",
    "        all_pivots_dict.append(pivot)\n",
    "\n",
    "    levels = window_shifting_method_sr(df, window)\n",
    "    for level in levels:\n",
    "        point = np.round(level[1], 2)\n",
    "        \n",
    "        pivot = {}\n",
    "        pivot[\"type\"] = \"SR - window shifting method\"\n",
    "        pivot[\"date\"]=level[0].to_pydatetime()\n",
    "        pivot[\"level\"] = point\n",
    "        all_pivots_dict.append(pivot)\n",
    "        \n",
    "    return all_pivots_dict\n",
    "\n",
    "def _find_nearest_index(levels, value):\n",
    "    array = np.asarray(levels)\n",
    "    idx = (np.abs(levels - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def shrink_list(levels, ltp, items_count=10):\n",
    "    idx = _find_nearest_index(levels, ltp)\n",
    "    \n",
    "    min_idx = idx-items_count\n",
    "    max_idx = idx+items_count\n",
    "    \n",
    "    if min_idx < 0:\n",
    "        min_idx = 0\n",
    "        \n",
    "    if max_idx > len(levels)-1:\n",
    "        max_idx = len(levels)-1\n",
    "        \n",
    "    return levels[min_idx:max_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(symbol, period=\"2y\", interval=\"1d\", start_date=None, end_date=None):\n",
    "  df = yf.download(tickers=symbol, interval=interval, period=period, start=start_date, end=end_date)\n",
    "  df['Date'] = pd.to_datetime(df.index)\n",
    "  df['Date'] = df['Date'].apply(mpl_dates.date2num)\n",
    "  df = df.loc[:,['Date', 'Open', 'high', 'low', 'Close']]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# symbol = 'TCS.NS'\n",
    "# symbol = '^NSEBANK'\n",
    "symbol = \"^NSEI\"\n",
    "df_y = get_stock_price(symbol, \"2y\", \"1d\")\n",
    "df_h = get_stock_price(symbol, \"6mo\", \"1h\")\n",
    "df_15m = get_stock_price(symbol, \"1mo\", \"15m\")\n",
    "df_5m = get_stock_price(symbol, \"7d\", \"5m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = sanitize(df_y)\n",
    "df_h = sanitize(df_h)\n",
    "df_15m = sanitize(df_15m)\n",
    "df_5m = sanitize(df_5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18311.25\n",
      "[17959.0, 17989.15, 18023.0, 18049.95, 18087.95, 18130.7, 18175.4, 18211.75, 18254.35, 18282.0, 18311.0, 18362.0, 18399.0]\n"
     ]
    }
   ],
   "source": [
    "levels = []\n",
    "\n",
    "ml = monthly_levels(df_y)\n",
    "levels.extend(ml)\n",
    "#print([x[\"level\"] for x in ml])\n",
    "\n",
    "ml = weekly_levels(df_y)\n",
    "levels.extend(ml)\n",
    "#print([x[\"level\"] for x in ml])\n",
    "\n",
    "ml = firty_two_week_levels(df_y)\n",
    "levels.extend(ml)\n",
    "#print([x[\"level\"] for x in ml])\n",
    "\n",
    "ml = get_support_resistance(df_y)\n",
    "levels.extend(ml)\n",
    "#print([x[\"level\"] for x in ml])\n",
    "\n",
    "ml = get_support_resistance(df_h)\n",
    "levels.extend(ml)\n",
    "#print([x[\"level\"] for x in ml])\n",
    "\n",
    "ml = get_support_resistance(df_15m)\n",
    "levels.extend(ml)\n",
    "#print([x[\"level\"] for x in ml])\n",
    "\n",
    "l = [x[\"level\"] for x in levels]\n",
    "\n",
    "price = df_5m.iloc[-1][\"close\"]\n",
    "\n",
    "l = remove_noise(df_15m, l, price)\n",
    "l.sort()\n",
    "\n",
    "print(price)\n",
    "print(shrink_list(l, price))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52f058016e79b0cb6f4bc1fb0cbaec4eb0fb60249ee39701686a66fe42631fb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
